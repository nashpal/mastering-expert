/*
  ==============================================================================

    This file was auto-generated by the Introjucer!

    It contains the basic framework code for a JUCE plugin processor.

  ==============================================================================
*/

#include "PluginProcessor.h"
#include "PluginEditor.h"
#include <complex>

//==============================================================================
TestPluginAudioProcessor::TestPluginAudioProcessor()
{

}

TestPluginAudioProcessor::~TestPluginAudioProcessor()
{
}

//==============================================================================
const String TestPluginAudioProcessor::getName() const
{
    return JucePlugin_Name;
}


const String TestPluginAudioProcessor::getInputChannelName (int channelIndex) const
{
    return String (channelIndex + 1);
}

const String TestPluginAudioProcessor::getOutputChannelName (int channelIndex) const
{
    return String (channelIndex + 1);
}

bool TestPluginAudioProcessor::isInputChannelStereoPair (int index) const
{
    return true;
}

bool TestPluginAudioProcessor::isOutputChannelStereoPair (int index) const
{
    return true;
}

bool TestPluginAudioProcessor::acceptsMidi() const
{
   #if JucePlugin_WantsMidiInput
    return true;
   #else
    return false;
   #endif
}

bool TestPluginAudioProcessor::producesMidi() const
{
   #if JucePlugin_ProducesMidiOutput
    return true;
   #else
    return false;
   #endif
}

bool TestPluginAudioProcessor::silenceInProducesSilenceOut() const
{
    return false;
}

double TestPluginAudioProcessor::getTailLengthSeconds() const
{
    return 0.0;
}

int TestPluginAudioProcessor::getNumPrograms()
{
    return 1;   // NB: some hosts don't cope very well if you tell them there are 0 programs,
                // so this should be at least 1, even if you're not really implementing programs.
}

int TestPluginAudioProcessor::getCurrentProgram()
{
    return 0;
}

void TestPluginAudioProcessor::setCurrentProgram (int index)
{
}

const String TestPluginAudioProcessor::getProgramName (int index)
{
    return String();
}

void TestPluginAudioProcessor::changeProgramName (int index, const String& newName)
{
}

//==============================================================================
void TestPluginAudioProcessor::prepareToPlay (double sampleRate, int samplesPerBlock)
{
    // Use this method as the place to do any pre-playback
    // initialisation that you need..
    int fftOrder = log2f(samplesPerBlock);
    forwardFFT = new FFT(fftOrder, false);
    inverseFFT = new FFT(fftOrder, true);
    forwardLeftFFTData = new float[2 * samplesPerBlock]; // To hold real and Complex
    forwardRightFFTData = new float[2 * samplesPerBlock]; // To hold real and Complex
    multipliedFFT = new float[2 * samplesPerBlock];
}

void TestPluginAudioProcessor::releaseResources()
{
    // When playback stops, you can use this as an opportunity to free up any
    // spare memory, etc.
    delete forwardFFT;
    delete inverseFFT;
    delete [] forwardLeftFFTData;
    delete [] forwardRightFFTData;
    delete [] multipliedFFT;

}

void TestPluginAudioProcessor::processBlock (AudioSampleBuffer& buffer, MidiBuffer& midiMessages)
{
    // In case we have more outputs than inputs, this code clears any output
    // channels that didn't contain input data, (because these aren't
    // guaranteed to be empty - they may contain garbage).
    // I've added this to avoid people getting screaming feedback
    // when they first compile the plugin, but obviously you don't need to
    // this code if your algorithm already fills all the output channels.
    
    dynamicRangeCounter++;
    
    const int numSamples = buffer.getNumSamples();
    
    // Just need 100 points for the vector scope
    int vectorScopeStride = floorf(numSamples / numberVectorPoints);
    int vectorScopeCounter = 0;
    
//    for (int i = getNumInputChannels(); i < getNumOutputChannels(); ++i)
//        buffer.clear (i, 0, buffer.getNumSamples());

    // Get left channel FFT (used for logo).
    const float* channelData = buffer.getReadPointer (0);
    zeromem (forwardLeftFFTData, numSamples * sizeof (float));
    memcpy (forwardLeftFFTData, channelData, numSamples * sizeof(float));
    
    // Now get right channel.
    channelData = buffer.getReadPointer (1);
    zeromem (forwardRightFFTData, numSamples * sizeof (float));
    memcpy (forwardRightFFTData, channelData, numSamples * sizeof(float));

    forwardFFT->performRealOnlyForwardTransform(forwardLeftFFTData);
    forwardFFT->performRealOnlyForwardTransform(forwardRightFFTData);
    
    // TODO: Use better bins or aaverage across bins.
    // Maybe don't need this every call.
    // We've only got 8 bars in the logo. Get bins at 1,2,4,8, ...
    for (int i = 0, j = 1; i < 8; i++, j*=2)
    {
        std::complex<float> val(((FFT::Complex*)forwardLeftFFTData)[j].r, ((FFT::Complex*)forwardLeftFFTData)[j].i);
        logoFFTBins[i] = int(std::abs(val)); // Get magnitude
    }
    
    // Effectively Rxx(0) is the energy in left channel. See Cross correlation comments below.
    float leftEnergy = 0;
    
    // Effectively Ryy(0) is the energy in right channel.
    float rightEnergy = 0;
    
    float Rxy0 = 0;
    
    // Hold the sum of all summed abs L/R samples for average.
    float blockAbsFrameSum = 0;
    
    // Hold the block's max sample value from left or right.
    float blockMax = 0;

    
    if (getNumInputChannels() == 2 && getNumOutputChannels() == 2)
    {
        for (int i = 0; i < numSamples; ++i)
        {
            float* leftChannelData = buffer.getWritePointer (0);
            float* rightChannelData = buffer.getWritePointer (1);

            
            // ************ Cross correlation ************
            
            // Cross correlation between l and r is Rxy(0) = Sum (x(n) * y(n)) (left = x, right = y).
            // Normalised to (-1, 1) is Rxy(0) / Sqrt(Rxx(0) Ryy(0)).
            // e.g. see p 114-116 Ch.2 DSP Proakis/Manolakis 2nd Edition.
            
//            std::complex<float> leftVal(((FFT::Complex*)forwardLeftFFTData)[i].r, ((FFT::Complex*)forwardLeftFFTData)[i].i);
//            std::complex<float> rightVal(((FFT::Complex*)forwardRightFFTData)[i].r, ((FFT::Complex*)forwardRightFFTData)[i].i);
//            
//            std::complex<float> product = leftVal * rightVal;
//            ((FFT::Complex*)multipliedFFT)[i].r = product.real();
//            ((FFT::Complex*)multipliedFFT)[i].i = product.imag();
            
            // Now need energy of l and r
            leftEnergy += (leftChannelData[i] * leftChannelData[i]);
            rightEnergy += (rightChannelData[i] * rightChannelData[i]);
            Rxy0 += leftChannelData[i] * rightChannelData[i];
        
            // ************ Headroom! ************

            headroomBreached = (std::abs(leftChannelData[i]) > 0.5 || std::abs(rightChannelData[i]) > 0.5) ? true : false;

            
            // Get the maximum sample in this block for dynamic range calculation.
            if (blockMax < std::abs(leftChannelData[i]))
            {
                blockMax = std::abs(leftChannelData[i]);
            }
            if (blockMax < std::abs(rightChannelData[i]))
            {
                blockMax = std::abs(rightChannelData[i]);
            }
           
            float frameSum = leftChannelData[i] + rightChannelData[i];
            float absFrameSum = std::abs(leftChannelData[i]) + std::abs(rightChannelData[i]);
            blockAbsFrameSum += absFrameSum;
            
            // ************ Mono playback! ************
            if (mono)
            {
                float frameSumAverage = frameSum / 2.f;
            
                leftChannelData[i] = frameSumAverage;
                rightChannelData[i] = frameSumAverage;
                
            }
            
            // ************ Vectorscope ************
            if (i % vectorScopeStride == 0)
            {
                vectorScopePoints[vectorScopeCounter++] = juce::Point<float>(leftChannelData[i], rightChannelData[i]);
            }
            
//            channelData[i] *= gain->getValue();
        }
    }
    
    // Calculate inverse FFT for cross correlation un-normalised value.
//    inverseFFT->performRealOnlyInverseTransform(multipliedFFT);
    
    // Calculate RMS
    leftRMS = sqrtf(leftEnergy / numSamples);
    rightRMS = sqrtf(rightEnergy / numSamples);
    
    // Calculate average abs sample value for this block
    float blockAverage = (blockAbsFrameSum / 2) / static_cast<float>(numSamples);
    
    if (dynamicRangeCounter < 100)
    {
        // Use this value to get dB, i.e. 20log(blockMax/blockAverage).
        if (blockAverage == 0)
        {
            blockAverage = 0.001;
        }
        if (blockMax == 0)
        {
            blockMax = 0.001;
        }
        
//        float val = 20 * log10f(blockMax / blockAverage);
        dynamicRange[dynamicRangeCounter] = blockMax / blockAverage;
        
        // Again, see Proakis.
        if (leftEnergy == 0 || rightEnergy == 0)
        {
            stereoCorrelationConvolution[dynamicRangeCounter] = 0;
        } else
        {
            stereoCorrelationConvolution[dynamicRangeCounter] = Rxy0/(sqrtf(leftEnergy * rightEnergy));
        }
        
    } else
    {
        // Notify the editor to check the average value of dynamicRange and stereo correlation.
        sendChangeMessage();
        dynamicRangeCounter = 0;
    }
    
    
    // ask the host for the current time.
    AudioPlayHead::CurrentPositionInfo newTime;
    
    if (getPlayHead() != nullptr && getPlayHead()->getCurrentPosition (newTime))
    {
        // Successfully got the current time from the host..
        lastPosInfo = newTime;
    }
    else
    {
        // If the host fails to fill-in the current time, we'll just clear it to a default..
        lastPosInfo.resetToDefault();
    }
    
}

//==============================================================================
bool TestPluginAudioProcessor::hasEditor() const
{
    return true; // (change this to false if you choose to not supply an editor)
}

AudioProcessorEditor* TestPluginAudioProcessor::createEditor()
{
    return new TestPluginAudioProcessorEditor (*this);
}

//==============================================================================
void TestPluginAudioProcessor::getStateInformation (MemoryBlock& destData)
{
    // You should use this method to store your parameters in the memory block.
    // You could do that either as raw data, or use the XML or ValueTree classes
    // as intermediaries to make it easy to save and load complex data.
}

void TestPluginAudioProcessor::setStateInformation (const void* data, int sizeInBytes)
{
    // You should use this method to restore your parameters from this memory block,
    // whose contents will have been created by the getStateInformation() call.
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new TestPluginAudioProcessor();
}
